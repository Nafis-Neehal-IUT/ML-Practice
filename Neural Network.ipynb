{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Initialize Boring Stuffs </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADdhJREFUeJzt3X+MVfWZx/HPUwoaoP7A6ghWS1vJRuUPqxOzibLxR0Tb\nGJFECCRUNjY7TcDEmv1D4z8l2TQas7huTKyhOoEmxbZRUVIb24Zs1lGbCWiaAmVpCY4tDAyrVLHE\niMCzf8yZzYhzv+dy7/k1PO9XQu6957nnnCcnfOace88592vuLgDxfKHuBgDUg/ADQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFCEHwjqi1WuzMy4nBAombtbO+/ras9vZreb2W4z22NmD3WzLADVsk6v7Tez\nKZL+JOlWSfskbZW03N3/mJiHPT9Qsir2/NdJ2uPue939mKSfSVrUxfIAVKib8F8i6a/jXu/Lpn2G\nmfWZ2TYz29bFugAUrJsv/CY6tPjcYb27r5O0TuKwH2iSbvb8+yRdOu71VyQNd9cOgKp0E/6tkuaZ\n2dfMbJqkZZI2F9MWgLJ1fNjv7sfN7D5Jv5Y0RVK/u+8srDMAper4VF9HK+MzP1C6Si7yATB5EX4g\nKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8QVKVDdKN6U6ZMSdYfe+yxZH3BggXJem9vb7I+MDDQsrZ69erkvDt27EjW0R32\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVFej9JrZkKSPJJ2QdNzdkyd9GaW3HFOnTm1ZW79+fXLe\n5cuXJ+uvvPJKsv7BBx8k60uXLm1ZO3bsWHLeJUuWJOuvvvpqsh5Vu6P0FnGRz03u/l4BywFQIQ77\ngaC6Db9L+o2ZvWVmfUU0BKAa3R72X+/uw2Z2kaTfmtn/uPtr49+Q/VHgDwPQMF3t+d19OHs8JGmT\npOsmeM86d+/N+zIQQLU6Dr+ZzTCzL409l7RQErdhAZNEN4f9PZI2mdnYcja6O+degEmiq/P8p70y\nzvOX4pFHHmlZe/DBB5PzPv3008n6qlWrOuppzJYtW1rWbrrppuS8R48eTdbnz5+frL/77rvJ+pmq\n3fP8nOoDgiL8QFCEHwiK8ANBEX4gKMIPBMVPd08CixcvTtYfeOCBlrXt27cn573//vs76qldw8PD\nLWuHDx9Ozjtr1qxk/e67707W165dm6xHx54fCIrwA0ERfiAowg8ERfiBoAg/EBThB4Lilt4GOPvs\ns5P1rVu3JutXXXVVy9oNN9yQnPfNN99M1ss0d+7cZD2vt/fffz9Zv/baa1vW8n42fDLjll4ASYQf\nCIrwA0ERfiAowg8ERfiBoAg/EBT38zdA3j31qfP4ktTf39+yNjg42FFPVThy5EhX8+dtlzlz5rSs\nDQ0NdbXuMwF7fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IKvc8v5n1S7pD0iF3n59NmyXp55LmShqS\ntNTd/1Zem5Pb9OnTk/UVK1Z0tfzUEN0nTpzoatllOuecc5L1iy++uKJOYmpnz79e0u2nTHtI0hZ3\nnydpS/YawCSSG353f03SqUOrLJK0IXu+QdJdBfcFoGSdfubvcfcDkpQ9XlRcSwCqUPq1/WbWJ6mv\n7PUAOD2d7vlHzGy2JGWPh1q90d3XuXuvu/d2uC4AJeg0/Jslrcyer5T0cjHtAKhKbvjN7DlJv5P0\nD2a2z8y+K+lRSbea2Z8l3Zq9BjCJ5H7md/flLUq3FNzLGWvVqlXJet596c8880yyzr3p6ARX+AFB\nEX4gKMIPBEX4gaAIPxAU4QeC4qe7K5A3BHee3bt3J+tNvm03Zc2aNV3N/+GHHybrH3/8cVfLP9Ox\n5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoDjPX4FFixZ1Nf9LL71UUCfNMm/evK7mHxgYSNZHRka6\nWv6Zjj0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFef4C9PT0JOuXX355sv7OO+8k6wcPHjztniYD\nM+uqPjg4WGQ74bDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgcs/zm1m/pDskHXL3+dm0NZL+RdL/\nZm972N1/VVaTk527J+s7d+5M1o8ePVpkO5WaPn16y9qFF16YnDdvu+3fv7+jnjCqnT3/ekm3TzD9\nP9z96uwfwQcmmdzwu/trkg5X0AuACnXzmf8+M/uDmfWb2fmFdQSgEp2G/0eSviHpakkHJK1t9UYz\n6zOzbWa2rcN1AShBR+F39xF3P+HuJyX9WNJ1ifeuc/ded+/ttEkAxeso/GY2e9zLxZJ2FNMOgKq0\nc6rvOUk3Svqyme2T9ANJN5rZ1ZJc0pCk75XYI4AS5Ibf3ZdPMPnZEnqZtM4666xkfcaMGcn6nDlz\nimynUc4999yWtfPOO6+rZe/du7er+aPjCj8gKMIPBEX4gaAIPxAU4QeCIvxAUPx0dwGOHz+erB87\ndqyiTprn5ptvblm74IILkvPmbbfh4eGOesIo9vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTn+Qsw\nbdq0ZD3vlt7J7JZbbknWn3rqqY6XvXZty1+HkyTt2bOn42WDPT8QFuEHgiL8QFCEHwiK8ANBEX4g\nKMIPBMV5/gZIDWMt5f80+CeffFJkO59xzTXXJOubNm1K1mfOnNmy9vrrryfnffLJJ5N1dIc9PxAU\n4QeCIvxAUIQfCIrwA0ERfiAowg8ElXue38wulfQTSRdLOilpnbv/p5nNkvRzSXMlDUla6u5/K6/V\n5tq/f3+yPjAwkKwvWLAgWb/tttuS9c2bNyfrKXm/nX/nnXcm66nz+JL0xhtvtKzde++9yXkPHjyY\nrKM77ez5j0v6V3e/QtI/SlptZldKekjSFnefJ2lL9hrAJJEbfnc/4O5vZ88/krRL0iWSFknakL1t\ng6S7ymoSQPFO6zO/mc2V9E1Jg5J63P2ANPoHQtJFRTcHoDxtX9tvZjMlvSDp++5+xMzana9PUl9n\n7QEoS1t7fjObqtHg/9TdX8wmj5jZ7Kw+W9KhieZ193Xu3uvuvUU0DKAYueG30V38s5J2ufvj40qb\nJa3Mnq+U9HLx7QEoSzuH/ddL+o6k7Wb2+2zaw5IelfQLM/uupL9IWlJOi8336aefJusbN25M1vNO\n9T3xxBMdr3/hwoXJeVesWJGs550KzDvNmeqdn96uV2743f11Sa0+4Kd/tB1AY3GFHxAU4QeCIvxA\nUIQfCIrwA0ERfiAoc/fqVmZW3coa5LLLLkvWd+zYkazn3TZbppMnTybry5YtS9aff/75IttBG9y9\nrWvv2fMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCc52+Anp6eZP2KK65I1u+5556WtSuvvDI57/Dw\ncLL++OOPJ+t5w2yjepznB5BE+IGgCD8QFOEHgiL8QFCEHwiK8ANBcZ4fOMNwnh9AEuEHgiL8QFCE\nHwiK8ANBEX4gKMIPBJUbfjO71Mz+y8x2mdlOM7s/m77GzPab2e+zf98uv10ARcm9yMfMZkua7e5v\nm9mXJL0l6S5JSyX93d3/ve2VcZEPULp2L/L5YhsLOiDpQPb8IzPbJemS7toDULfT+sxvZnMlfVPS\nYDbpPjP7g5n1m9n5LebpM7NtZratq04BFKrta/vNbKak/5b0Q3d/0cx6JL0nySX9m0Y/GtybswwO\n+4GStXvY31b4zWyqpF9K+rW7f+4XHbMjgl+6+/yc5RB+oGSF3dhjZibpWUm7xgc/+yJwzGJJ6aFm\nATRKO9/23yBpQNJ2SWPjNT8sabmkqzV62D8k6XvZl4OpZbHnB0pW6GF/UQg/UD7u5weQRPiBoAg/\nEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgq9wc8C/aepHfHvf5yNq2J\nmtpbU/uS6K1TRfb21XbfWOn9/J9budk2d++trYGEpvbW1L4keutUXb1x2A8ERfiBoOoO/7qa15/S\n1N6a2pdEb52qpbdaP/MDqE/de34ANakl/GZ2u5ntNrM9ZvZQHT20YmZDZrY9G3m41iHGsmHQDpnZ\njnHTZpnZb83sz9njhMOk1dRbI0ZuTowsXeu2a9qI15Uf9pvZFEl/knSrpH2Stkpa7u5/rLSRFsxs\nSFKvu9d+TtjM/knS3yX9ZGw0JDN7TNJhd380+8N5vrs/2JDe1ug0R24uqbdWI0v/s2rcdkWOeF2E\nOvb810na4+573f2YpJ9JWlRDH43n7q9JOnzK5EWSNmTPN2j0P0/lWvTWCO5+wN3fzp5/JGlsZOla\nt12ir1rUEf5LJP113Ot9ataQ3y7pN2b2lpn11d3MBHrGRkbKHi+quZ9T5Y7cXKVTRpZuzLbrZMTr\notUR/olGE2nSKYfr3f0aSd+StDo7vEV7fiTpGxodxu2ApLV1NpONLP2CpO+7+5E6exlvgr5q2W51\nhH+fpEvHvf6KpOEa+piQuw9nj4ckbdLox5QmGRkbJDV7PFRzP//P3Ufc/YS7n5T0Y9W47bKRpV+Q\n9FN3fzGbXPu2m6ivurZbHeHfKmmemX3NzKZJWiZpcw19fI6Zzci+iJGZzZC0UM0bfXizpJXZ85WS\nXq6xl89oysjNrUaWVs3brmkjXtdykU92KuMJSVMk9bv7DytvYgJm9nWN7u2l0TseN9bZm5k9J+lG\njd71NSLpB5JekvQLSZdJ+oukJe5e+RdvLXq7Uac5cnNJvbUaWXpQNW67Ike8LqQfrvADYuIKPyAo\nwg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQf0fyfEVBqxqQmwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15103849b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libraries and stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import mnist from local directory\n",
    "data = pd.read_csv('mnist/train.csv')\n",
    "\n",
    "#data_target_split\n",
    "y = np.array(data['label'])\n",
    "X = np.array(data[data.columns[1:]])\n",
    "X = X / 255\n",
    "\n",
    "#image checking\n",
    "print(X.shape)\n",
    "first_sample = np.reshape(X[5], (28, 28))\n",
    "plt.imshow(first_sample, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Network Structure </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42001 [[0.04990874]\n",
      " [0.97291619]\n",
      " [0.60080002]\n",
      " [0.64677699]\n",
      " [0.98157337]\n",
      " [0.2503338 ]\n",
      " [0.32931869]\n",
      " [0.08767584]\n",
      " [0.00243202]\n",
      " [0.5043112 ]]\n"
     ]
    }
   ],
   "source": [
    "#initialize the network\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, layer_parameter):\n",
    "        if(layer_parameter[1]!='none'): \n",
    "            self.activations_for_this_layer = np.zeros(layer_parameter[0])\n",
    "        self.number_of_nodes = layer_parameter[0]\n",
    "        self.activation_function = layer_parameter[1]\n",
    "        self.weights_from_previous_layer = layer_parameter[2]\n",
    "        self.biases_for_this_layer = layer_parameter[3]\n",
    "        \n",
    "class NeuralNetwork:\n",
    "    \n",
    "    #constructor\n",
    "    def __init__(self, network_parameter):\n",
    "        self.number_of_hidden_layers = network_parameter[0]\n",
    "        self.hidden_layer_size = network_parameter[1]\n",
    "        self.output_size = network_parameter[2]\n",
    "        self.layers = []\n",
    "        \n",
    "    #activation functions\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return np.divide(1, np.add(1, np.exp(np.negative(x))))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp = np.exp(x)\n",
    "        if isinstance(x[0], np.ndarray):\n",
    "            return exp/np.sum(exp, axis=1, keepdims=True)\n",
    "        else:\n",
    "            return exp/np.sum(exp, keepdims=True)\n",
    "    \n",
    "    #def calculate_loss \n",
    "    #def mini_batch_gradient_descent()\n",
    "    #def back_propagation\n",
    "    #def performance_measurement\n",
    "    \n",
    "    #network structure define\n",
    "    def structure_define(self, nn):\n",
    "            #create input layer\n",
    "            input_layer = Layer([784, 'none', [], []])\n",
    "            nn.layers.append(input_layer)\n",
    "\n",
    "            #create hidden layer 1\n",
    "            np.random.seed(1)\n",
    "            hidden_layer_1_weights = np.random.randn(784, 16)\n",
    "            hidden_layer_1_biases = np.random.randn(16, 1)\n",
    "            hidden_layer_1 = Layer([16, 'ReLU', hidden_layer_1_weights, hidden_layer_1_biases])\n",
    "            nn.layers.append(hidden_layer_1)\n",
    "\n",
    "            #create hidden layer 2\n",
    "            np.random.seed(2)\n",
    "            hidden_layer_2_weights = np.random.randn(16, 16)\n",
    "            hidden_layer_2_biases = np.random.randn(16, 1)\n",
    "            hidden_layer_2 = Layer([16, 'ReLU', hidden_layer_2_weights, hidden_layer_2_biases])\n",
    "            nn.layers.append(hidden_layer_2)\n",
    "\n",
    "            #create output layer\n",
    "            np.random.seed(3)\n",
    "            output_layer_weights = np.random.randn(16, 10)\n",
    "            output_layer_biases = np.random.randn(10, 1)\n",
    "            output_layer = Layer([10, 'ReLU', output_layer_weights, output_layer_biases])\n",
    "            nn.layers.append(output_layer)\n",
    "            \n",
    "    def forward_propagation(self, sample_image):\n",
    "        counter = 1\n",
    "        for sample_image in X:\n",
    "            counter = counter + 1\n",
    "            sample_image = np.reshape(sample_image, (784, 1))\n",
    "            hidden_layer_1.activations_for_this_layer = self.sigmoid(np.add(np.matmul(np.transpose(hidden_layer_1.\\\n",
    "                                                        weights_from_previous_layer),sample_image), \\\n",
    "                                                        hidden_layer_1.biases_for_this_layer))\n",
    "            hidden_layer_2.activations_for_this_layer = self.sigmoid(np.add(np.matmul(np.transpose(hidden_layer_2.\\\n",
    "                                                        weights_from_previous_layer),\\\n",
    "                                                        hidden_layer_1.activations_for_this_layer), \\\n",
    "                                                        hidden_layer_2.biases_for_this_layer))\n",
    "            output_layer.activations_for_this_layer   = self.sigmoid(np.add(np.matmul(np.transpose(output_layer.\\\n",
    "                                                        weights_from_previous_layer),\\\n",
    "                                                        hidden_layer_2.activations_for_this_layer), \\\n",
    "                                                        output_layer.biases_for_this_layer))\n",
    "        print(counter, output_layer.activations_for_this_layer)\n",
    "\n",
    "#initialize network\n",
    "neural_net = NeuralNetwork([2, 16, 10])\n",
    "neural_net.structure_define(neural_net)\n",
    "\n",
    "#forward_propagation\n",
    "neural_net.forward_propagation(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
